# whisper_testing
Speech Recognition Tool: Multilingual, Multitasking translation and trascription
encoder-decoder Transformer is the basic technique where the architecture is comprising of.

Common evaluation metrics and it's results:
1. WER method.
2. Zero-shot Evaluation: yes
3. Multi lingual method: results are below
   ![image](https://github.com/manikandanhereby/whisper_testing/assets/52741580/845d1609-9bb6-458b-97b1-2906751fd0e9)



We can use OpenAI's speech recognition model
It can perform speech recognition, translation and language identification.
currently supports 96 languages.
I used pytorch to use it locally.


<img width="958" alt="image" src="https://github.com/manikandanhereby/whisper_testing/assets/52741580/c2ddf07e-3156-4d36-b87c-c7ed917ed347">


<img width="593" alt="image" src="https://github.com/manikandanhereby/whisper_testing/assets/52741580/77732529-f9c1-4577-a61d-eb747985a788">


<img width="513" alt="image" src="https://github.com/manikandanhereby/whisper_testing/assets/52741580/da663ffe-51f7-4677-9bff-48ed97160a30">
