# whisper_testing
Speech Recognition Tool: Multilingual, Multitasking translation and trascription
encoder-decoder Transformer is the basic technique where the architecture is comprising of.
1. Zero-shot Evaluation:
The goal of Whisper is to develop a single robust speech processing system that works reliably without the need for dataset specific fine-tuning to achieve high-quality results on specific distributions. To study this capability, we reuse a wide set of existing speech processing datasets to
check whether Whisper is able to generalize well across domains, tasks, and languages. Instead of using the standard evaluation protocol for these datasets, which include both a train and test split, we evaluate Whisper in a zero-shot setting without using any of the training data for each of these datasets so that we are measuring broad generalization.


We can use OpenAI's speech recognition model
It can perform speech recognition, translation and language identification.
currently supports 96 languages.
I used pytorch to use it locally.


<img width="958" alt="image" src="https://github.com/manikandanhereby/whisper_testing/assets/52741580/c2ddf07e-3156-4d36-b87c-c7ed917ed347">


<img width="593" alt="image" src="https://github.com/manikandanhereby/whisper_testing/assets/52741580/77732529-f9c1-4577-a61d-eb747985a788">


<img width="513" alt="image" src="https://github.com/manikandanhereby/whisper_testing/assets/52741580/da663ffe-51f7-4677-9bff-48ed97160a30">
